{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Notebook to try CNN and DistilBERT models on the dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a924358f895f94c3"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "#imports\n",
    "import pandas as pd\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import DistilBertForSequenceClassification, DistilBertTokenizer, DistilBertConfig, AdamW\n",
    "import torch"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-07T21:53:53.438612Z",
     "start_time": "2024-04-07T21:53:50.391102Z"
    }
   },
   "id": "1dc35ccc97e84424"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                text  label\n0  db.mycol.find({$and:[{\"by\":\"tutorials point\"},...      0\n1  db.collection('users').findOne({\"\"username\"\": ...      1\n2       db.Document.find({ \"type\": { \"$gte\": \"\" } })      1\n3       db.Document.find({ \"type\": { \"$ne: 0 \"\" } })      1\n4  db.books.insert({ title: 'The Hobbit', author:...      0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>db.mycol.find({$and:[{\"by\":\"tutorials point\"},...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>db.collection('users').findOne({\"\"username\"\": ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>db.Document.find({ \"type\": { \"$gte\": \"\" } })</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>db.Document.find({ \"type\": { \"$ne: 0 \"\" } })</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>db.books.insert({ title: 'The Hobbit', author:...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import data\n",
    "data = pd.read_json('../data/jsonformatter.json')\n",
    "data.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-07T21:35:33.860335Z",
     "start_time": "2024-04-07T21:35:33.855488Z"
    }
   },
   "id": "3acb95e5123002f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Preprocess the data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2b7055344c717e8c"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text     0\n",
      "label    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "print(data.isnull().sum())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-07T21:35:33.883236Z",
     "start_time": "2024-04-07T21:35:33.861763Z"
    }
   },
   "id": "228481e1fb44348d"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/Users/purnimag/anaconda3/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# tokenize the data\n",
    "\n",
    "from transformers import DistilBertTokenizer\n",
    "import torch\n",
    "\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "input_ids = []\n",
    "attention_masks = []\n",
    "\n",
    "for query in data['text']:\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        query,\n",
    "                        add_special_tokens = True,\n",
    "                        max_length = 64,\n",
    "                        pad_to_max_length = True,\n",
    "                        return_attention_mask = True,\n",
    "                        return_tensors = 'pt',\n",
    "                   )\n",
    "    input_ids.append(encoded_dict['input_ids'])\n",
    "    attention_masks.append(encoded_dict['attention_mask'])\n",
    "    \n",
    "# Convert the lists into tensors\n",
    "input_ids = torch.cat(input_ids, dim=0)\n",
    "attention_masks = torch.cat(attention_masks, dim=0)\n",
    "labels = torch.tensor(data['label'].values)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-07T21:35:34.310507Z",
     "start_time": "2024-04-07T21:35:33.875940Z"
    }
   },
   "id": "97fa3c23e9b2d724"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Test and Train "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3e2886e512dd4bc"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# Split the data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_inputs, val_inputs, train_labels, val_labels, train_masks, val_masks = train_test_split(input_ids, labels, attention_masks, test_size=0.2)\n",
    "\n",
    "train_masks,val_masks, _, _ = train_test_split(attention_masks, labels, test_size=0.2)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-07T21:51:53.234551Z",
     "start_time": "2024-04-07T21:51:52.450111Z"
    }
   },
   "id": "61860542186b1120"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Create the DataLoader for the training set"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "50a1a44c620ccaca"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "#train\n",
    "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "#test\n",
    "val_data = TensorDataset(val_inputs, val_masks, val_labels)\n",
    "val_sampler = SequentialSampler(val_data)\n",
    "val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=batch_size)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-07T21:54:44.040238Z",
     "start_time": "2024-04-07T21:54:44.036927Z"
    }
   },
   "id": "c6a67b669eeec45f"
  },
  {
   "cell_type": "markdown",
   "source": [
    " Model Training and Evaluation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e44afb3470727250"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "92c8653f0de24bad"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
